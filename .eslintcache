[{"D:\\Study\\React\\audio-app\\src\\index.js":"1","D:\\Study\\React\\audio-app\\src\\reportWebVitals.js":"2","D:\\Study\\React\\audio-app\\src\\App.js":"3","D:\\Study\\React\\audio-app\\src\\home.tsx":"4","D:\\Study\\React\\audio-app\\src\\voiceAssistant.js":"5","D:\\Study\\React\\audio-app\\src\\voiceVisualizer.js":"6","D:\\Study\\React\\audio-app\\src\\listening\\listening.tsx":"7","D:\\Study\\React\\audio-app\\src\\speechComp\\speechComp.tsx":"8","D:\\Study\\React\\audio-app\\src\\Utils\\methodUtils.js":"9","D:\\Study\\React\\audio-app\\src\\facialRecognition\\authenticate.tsx":"10","D:\\Study\\React\\audio-app\\src\\facialRecognition.js":"11","D:\\Study\\React\\audio-app\\src\\speechComp\\speechAction.js":"12"},{"size":981,"mtime":1653068489509,"results":"13","hashOfConfig":"14"},{"size":362,"mtime":499162500000,"results":"15","hashOfConfig":"14"},{"size":10377,"mtime":1649847735166,"results":"16","hashOfConfig":"14"},{"size":1166,"mtime":1649803028668,"results":"17","hashOfConfig":"14"},{"size":5347,"mtime":1653860996190,"results":"18","hashOfConfig":"14"},{"size":792,"mtime":1650705415507,"results":"19","hashOfConfig":"14"},{"size":2274,"mtime":1653864332760,"results":"20","hashOfConfig":"14"},{"size":2382,"mtime":1653816059667,"results":"21","hashOfConfig":"14"},{"size":583,"mtime":1653823609805,"results":"22","hashOfConfig":"14"},{"size":2585,"mtime":1653637437374,"results":"23","hashOfConfig":"14"},{"size":2354,"mtime":1653636213962,"results":"24","hashOfConfig":"14"},{"size":904,"mtime":1653861110839,"results":"25","hashOfConfig":"14"},{"filePath":"26","messages":"27","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},"utvmey",{"filePath":"29","messages":"30","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},{"filePath":"31","messages":"32","errorCount":0,"fatalErrorCount":0,"warningCount":11,"fixableErrorCount":0,"fixableWarningCount":0,"source":"33","usedDeprecatedRules":"28"},{"filePath":"34","messages":"35","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"36","usedDeprecatedRules":"37"},{"filePath":"38","messages":"39","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"40","messages":"41","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"42","usedDeprecatedRules":"28"},{"filePath":"43","messages":"44","errorCount":0,"fatalErrorCount":0,"warningCount":6,"fixableErrorCount":0,"fixableWarningCount":0,"source":"45"},{"filePath":"46","messages":"47","errorCount":0,"fatalErrorCount":0,"warningCount":12,"fixableErrorCount":0,"fixableWarningCount":0,"source":"48"},{"filePath":"49","messages":"50","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"51","messages":"52","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"53"},{"filePath":"54","messages":"55","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"56","messages":"57","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"58"},"D:\\Study\\React\\audio-app\\src\\index.js",[],["59","60"],"D:\\Study\\React\\audio-app\\src\\reportWebVitals.js",[],"D:\\Study\\React\\audio-app\\src\\App.js",["61","62","63","64","65","66","67","68","69","70","71"],"import logo from './logo.svg';\nimport './App.css';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as speech from \"@tensorflow-models/speech-commands\"\nimport {useEffect, useState} from \"react\";\n\nfunction App() {\n\n  const [model, setModel] = useState(null);\n  const [action, setAction] = useState(null);\n  const [labels, setLabels] = useState(null);\n  const [modelTobuilded,setModelTobuilded] = useState(null);\n\n  const NUM_FRAMES = 3;\n  const INPUT_SHAPE = [NUM_FRAMES, 232, 1];\n  let examples = [];\n  let modelTobuild ;\n\n  const loadModel = async () => {\n    const recognizer = await speech.create('BROWSER_FFT');\n    console.log(\"Model Loaded\");\n    await recognizer.ensureModelLoaded();\n    setModel(recognizer);\n    setLabels(recognizer.words);\n    console.log(\"fffffd \",recognizer);\n  }\n\n  const recognizeCommands = async () =>{\n    console.log('Listening for commands')\n    model.listen(result=>{\n      console.log(Object.values(result.scores));\n      let scores = Array.from(result.scores).map((s, i) => ({score: s, word: model.words[i]}));\n      scores.sort((s1, s2) => s2.score - s1.score);\n      console.log('scores ',scores[0]);\n    }, {includeSpectrogram:true, probabilityThreshold:0.9});\n  };\n\n  const train = async () => {\n    console.log(examples);\n    const ys = tf.oneHot(examples.map(e => e.label), 3);\n    const xsShape = [examples.length, ...INPUT_SHAPE];\n    const xs = tf.tensor(flatten(examples.map(e => e.vals)), xsShape);\n    await modelTobuilded.fit(xs, ys, {\n      batchSize: 16,\n      epochs: 100,\n      callbacks: {\n        onEpochEnd: (epoch, logs) => {\n          console.log(\n              `Accuracy: ${(logs.acc * 100).toFixed(1)}% Epoch: ${epoch + 1}`);\n        }\n      }\n    });\n    tf.dispose([xs, ys]);\n  };\n\n  async function buildModel() {\n    modelTobuild = tf.sequential();\n    modelTobuild.add(tf.layers.depthwiseConv2d({\n      depthMultiplier: 8,\n      kernelSize: [NUM_FRAMES, 3],\n      activation: 'relu',\n      inputShape: INPUT_SHAPE\n    }));\n    modelTobuild.add(tf.layers.maxPooling2d({poolSize: [1, 2], strides: [2, 2]}));\n    modelTobuild.add(tf.layers.flatten());\n    modelTobuild.add(tf.layers.dense({units: 3, activation: 'softmax'}));\n    const optimizer = tf.train.adam(0.01);\n    modelTobuild.compile({\n      optimizer,\n      loss: 'categoricalCrossentropy',\n      metrics: ['accuracy']\n    });\n    setModelTobuilded(modelTobuild);\n  }\n\n  const setStateAsync = (state) => {\n    return new Promise((resolve) => {\n      this.setState(state, resolve)\n    });\n  }\n\n  function flatten(tensors) {\n    const size = tensors[0].length;\n    const result = new Float32Array(tensors.length * size);\n    tensors.forEach((arr, i) => result.set(arr, i * size));\n    return result;\n  }\n\n  const collectVoice = (label) => {\n    if(model != null) {\n      if (model.isListening()) {\n        return model.stopListening();\n      }\n      if (label == null) {\n        console.log(label);\n        return;\n      }\n      model.listen(async ({spectrogram: {frameSize, data}}) => {\n        console.log('fr : ', frameSize,\" da : \",data.subarray()[0], \" r : \",Math.round(data.subarray()[0] * 100) / 100);\n        if (data.subarray()[0] !== 0) {\n          //let result = [] ;\n          //for(var i in JSON.stringify(data))\n          //console.log(\"i : \",JSON.stringify(data) [i]);\n          //result.push([i, JSON.stringify(data) [i]]);\n\n          let vals = normalize(data.subarray(-frameSize * NUM_FRAMES));\n          //console.log(data.subarray());\n          //for(var i in vals)\n            //console.log(vals[i]);\n          examples.push({vals, label});\n          console.log(`${examples.length}`, \" examples for \", label);\n        }\n      }, {\n        overlapFactor: 0.5,\n        includeSpectrogram: true,\n        invokeCallbackOnNoiseAndUnknown: true\n      });\n      console.log(examples);\n    }\n  }\n\n  function normalize(x) {\n    const mean = -100;\n    const std = 10;\n    return x.map(x => (x - mean) / std);\n  }\n\n  function predict(){\n    let scores = Array.from(examples).map((s, i) => ({val: s, label: i}));\n    scores.sort((s1, s2) => s2.val - s1.val);\n    console.log(scores[0]);\n  }\n\n  function saveExemple(){\n    const element = document.createElement(\"a\");\n    const file = new Blob([JSON.stringify(examples)], {type: 'text/plain'});\n    element.href = URL.createObjectURL(file);\n    element.download = \"myFile.txt\";\n    document.body.appendChild(element);\n    element.click();\n  }\n\n  async function moveSlider(labelTensor) {\n    const label = (await labelTensor.data())[0];\n    console.log(label);\n    if (label == 2) {\n      return;\n    }\n    let delta = 0.1;\n    const prevValue = +document.getElementById('output').value;\n    document.getElementById('output').value =\n        prevValue + (label === 0 ? -delta : delta);\n  }\n\n  const listen = () => {\n    if (model.isListening()) {\n      model.stopListening();\n      console.log('Listen');\n      return;\n    }\n    console.log('Stop');\n\n    model.listen(async ({spectrogram: {frameSize, data}}) => {\n\n      const vals = normalize(data.subarray(-frameSize * NUM_FRAMES));\n      const input = tf.tensor(vals, [1, ...INPUT_SHAPE]);\n      const probs = modelTobuilded.predict(input);\n      const predLabel = probs.argMax(1);\n      const scores = probs.arraySync()[0];\n\n      console.log(scores);\n      const score = Array.from(scores).map((s, i) => ({score: s, word: i}));\n      score.sort((s1, s2) => s2.score - s1.score);\n      console.log(score[0].word);\n\n      //console.log('prelabel ',predLabel);\n      const labela = (await predLabel.data())[0];\n      console.log(labela);\n      //await moveSlider(predLabel);\n\n      tf.dispose([input, probs, predLabel]);\n    }, {\n      overlapFactor: 0.5,\n      includeSpectrogram: true,\n      invokeCallbackOnNoiseAndUnknown: true,\n      probabilityThershold: 0.8,\n    });\n  };\n\n  const testListen = async () => {\n    const baseRecognizer = await speech.create('BROWSER_FFT');\n    await baseRecognizer.ensureModelLoaded();\n    const transferRecognizer = baseRecognizer.createTransfer('colors');\n\n    await transferRecognizer.collectExample('red');\n    await transferRecognizer.collectExample('green');\n    await transferRecognizer.collectExample('blue');\n    await transferRecognizer.collectExample('red');\n\n    await transferRecognizer.collectExample('_background_noise_');\n    await transferRecognizer.collectExample('green');\n    await transferRecognizer.collectExample('blue');\n    await transferRecognizer.collectExample('_background_noise_');\n\n    console.log(transferRecognizer.countExamples());\n\n    await transferRecognizer.train({\n      epochs: 25,\n      callback: {\n        onEpochEnd: async (epoch, logs) => {\n          console.log(`Epoch ${epoch}: loss=${logs.loss}, accuracy=${logs.acc}`);\n        }\n      }\n    });\n\n    await transferRecognizer.listen(result => {\n\n      const words = transferRecognizer.wordLabels();\n\n      for (let i = 0; i < words; ++i) {\n        console.log(`score for word '${words[i]}' = ${result.scores[i]}`);\n      }\n    }, {probabilityThreshold: 0.75});\n\n    setTimeout(() => transferRecognizer.stopListening(), 10e3);\n  }\n\n  const exportFile = () => {\n    var rawFile = new XMLHttpRequest();\n    rawFile.open(\"GET\", `${window.location.origin}`+'\\\\myFile.txt', false);\n    rawFile.onreadystatechange = function ()\n    {\n      if(rawFile.readyState === 4)\n      {\n        if(rawFile.status === 200 || rawFile.status == 0)\n        {\n          var allText = rawFile.responseText;\n          examples = allText ;\n          console.log(allText);\n        }\n      }\n    }\n    rawFile.send(null);\n  }\n\n  const cleanData = () => {\n    let voir = examples.filter(e => e.label === 1);\n    console.log(voir.length);\n    let noise = examples.filter(e => e.label === 0);\n    console.log(voir[0].vals.json);\n    for(var i in voir)\n      for(var j of voir[i].vals){\n\n        console.log(j);\n      }\n    voir.forEach(e => {\n      //let index = noise.val.indexOf(e.val) ;\n      //console.log(e.vals);\n      noise.forEach(r => {\n        if(e.val === r.val){\n          //voir.splice(voir.indexOf(e),1);\n        }\n      });\n      //if(index !== -1) {\n        //voir.splice(voir.indexOf(e),1);\n      //}\n    });\n    console.log(voir.length);\n    console.log(noise.length);\n\n  };\n\n  useEffect(() => {\n    loadModel();\n    buildModel();\n    console.log(modelTobuild);\n  },[]);\n\n\n  return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n          <img src={logo} className=\"App-logo\" alt=\"logo\" />\n          <p>\n            Edit <code>src/App.js</code> and save to reload.\n          </p>\n          <button onClick={recognizeCommands}>Listening</button>\n          <button onMouseDown={() => collectVoice(0)} onMouseUp={() => collectVoice(0)}>SILENCE</button>\n          <button onMouseDown={() => collectVoice(1)} onMouseUp={() => collectVoice(1)}>ZERO</button>\n          <button onMouseDown={() => collectVoice(2)} onMouseUp={() => collectVoice(2)}>ONE</button>\n          <button onMouseDown={() => collectVoice(4)} onMouseUp={() => collectVoice(4)}>TWO</button>\n          <button onMouseDown={() => collectVoice(5)} onMouseUp={() => collectVoice(5)}>THREE</button>\n          <button onMouseDown={() => collectVoice(6)} onMouseUp={() => collectVoice(6)}>FOUR</button>\n          <button onMouseDown={() => collectVoice(7)} onMouseUp={() => collectVoice(7)}>FIVE</button>\n          <button onMouseDown={() => collectVoice(8)} onMouseUp={() => collectVoice(8)}>SIX</button>\n          <button onMouseDown={() => collectVoice(9)} onMouseUp={() => collectVoice(9)}>SEVEN</button>\n          <button onMouseDown={() => collectVoice(10)} onMouseUp={() => collectVoice(10)}>EIGHT</button>\n          <button onMouseDown={() => collectVoice(11)} onMouseUp={() => collectVoice(11)}>NINE</button>\n          <button onMouseDown={() => collectVoice(1)} onMouseUp={() => collectVoice(1)}>NOISE</button>\n\n\n          <button onClick={train}>Train</button>\n          <input type=\"range\" id=\"output\" min=\"0\" max=\"10\" step=\"0.1\"/>\n          <button onClick={listen}>Listen</button>\n          <button onClick={saveExemple}>save</button>\n          <button onClick={()=>model.stopListening()}>Stop</button>\n          <button onClick={saveExemple}>save</button>\n          <button onClick={exportFile}>export</button>\n          <button onClick={cleanData}>showList</button>\n\n        </header>\n\n      </div>\n  );\n}\n\nexport default App;\n","D:\\Study\\React\\audio-app\\src\\home.tsx",["72","73","74","75"],"import {useEffect, useState} from \"react\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\nimport * as SpeechCommands from \"@tensorflow-models/speech-commands\";\r\n\r\nimport VoiceModel from \"./My_Model/model.json\";\r\nimport VoiceModelMetadata from \"./My_Model/metadata.json\";\r\nimport VoiceAssistant from \"./voiceAssistant\";\r\n\r\nexport const HomePage = () => {\r\n\r\n    const [model, setModel] = useState(null);\r\n    let voiceAssistant;\r\n\r\n    async function buildModel() {\r\n        const recognizer = await SpeechCommands.create(\"BROWSER_FFT\",undefined,VoiceModel,VoiceModelMetadata);\r\n        await recognizer.ensureModelLoaded();\r\n        console.log(\"Model Loaded\");\r\n        return recognizer;\r\n    }\r\n\r\n    const startAssistance = async () => {\r\n        //const recognizer = await buildModel();\r\n        voiceAssistant = new VoiceAssistant();\r\n        voiceAssistant.start();\r\n        //recognizer.listen((result)=>{},null);\r\n    }\r\n\r\n    useEffect(()=> {\r\n        console.log('ooooo');\r\n    },[]);\r\n\r\n    return (\r\n        <div>\r\n            <h1>OK</h1>\r\n            <button onClick={startAssistance} >Start</button>\r\n        </div>\r\n    );\r\n\r\n};\r\nexport default HomePage ;",["76","77"],"D:\\Study\\React\\audio-app\\src\\voiceAssistant.js",[],"D:\\Study\\React\\audio-app\\src\\voiceVisualizer.js",["78"],"import Wave from \"wave-visualizer\";\r\n\r\nexport default class VoiceVisualizer {\r\n    constructor() {}\r\n\r\n    async openAudioStream() {\r\n        try {\r\n            this.audioStream = await navigator.mediaDevices.getUserMedia({\r\n                audio: true,\r\n            });\r\n        } catch (err) {\r\n            console.error(\"Cannot open Audio Stream \", err);\r\n        }\r\n    }\r\n\r\n    async startVisualization() {\r\n        await this.openAudioStream();\r\n\r\n        let wave = new Wave();\r\n\r\n        wave.fromStream(this.audioStream, \"output\", {\r\n            type: \"bars\",\r\n            colors: [\"white\", \"FFFFFF\"],\r\n            stroke: 1,\r\n        });\r\n    }\r\n\r\n    stopVisualization() {\r\n        this.audioStream.getTracks().forEach((track) => {\r\n            track.stop();\r\n        });\r\n    }\r\n}","D:\\Study\\React\\audio-app\\src\\listening\\listening.tsx",["79","80","81","82","83","84"],"import {useEffect, useState} from \"react\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\nimport * as SpeechCommands from \"@tensorflow-models/speech-commands\";\r\n\r\nimport VoiceModel from \"../My_Model/model.json\";\r\nimport VoiceModelMetadata from \"../My_Model/metadata.json\";\r\nimport VoiceAssistant from \"../voiceAssistant\";\r\n\r\nimport './listening.css'\r\nimport voiceVisualizer from \"../voiceVisualizer\";\r\nimport SpeechComp from \"../speechComp/speechComp\";\r\nimport {numberTab, sort} from \"../Utils/methodUtils\";\r\nimport voiceAssistant from \"../voiceAssistant\";\r\nimport {wordAction} from \"../speechComp/speechAction\";\r\n\r\nexport const Listening = () => {\r\n\r\n    let processingWord : any ;\r\n    let numDossier = \"\" ;\r\n\r\n    const [processWord, setProcessWord] = useState('null');\r\n\r\n    async function onListen(word:any) {\r\n        console.log(\"Word: \", word);\r\n        setProcessWord(word);\r\n\r\n        if(numberTab.includes(word)){\r\n            numDossier = numDossier.concat(sort().get(word));\r\n        }\r\n        if(word !== \"Bruit de fond\") {\r\n            if(processingWord !== word)\r\n            await wordAction({previousWord: processingWord, currentWord: word, number: numDossier});\r\n            processingWord = word;\r\n        }\r\n\r\n    }\r\n\r\n\r\n    const start = async () => {\r\n        console.log('ddddddd');\r\n        const visualizer = new voiceVisualizer();\r\n        await visualizer.startVisualization();\r\n        const assistant = new voiceAssistant();\r\n        assistant.beginAssistance(onListen);\r\n        console.log(sort().get('Un'));\r\n    }\r\n\r\n\r\n    return (\r\n        <div className=\"waveWrapper waveAnimation\">\r\n            <button onClick={()=> start()}>OK</button>\r\n            <div className=\"SpeechComp\">\r\n                <SpeechComp word={processWord}/>\r\n            </div>\r\n            <div className=\"\">\r\n                <div className=\"bgTop\">\r\n                    <div className=\"wave waveTop\"></div>\r\n                </div>\r\n                <div className=\"bgMiddle\">\r\n                    <div className=\"wave waveMiddle\"></div>\r\n                </div>\r\n                <div className=\"bgBottom\">\r\n                    <div className=\"wave waveBottom\"></div>\r\n                </div>\r\n            </div>\r\n        </div>\r\n    );\r\n\r\n};\r\nexport default Listening ;","D:\\Study\\React\\audio-app\\src\\speechComp\\speechComp.tsx",["85","86","87","88","89","90","91","92","93","94","95","96"],"import * as React from 'react';\r\nimport { Theme } from '@mui/material/styles';\r\nimport Box from '@mui/material/Box';\r\nimport Switch from '@mui/material/Switch';\r\nimport Paper from '@mui/material/Paper';\r\nimport Grow from '@mui/material/Grow';\r\nimport FormControlLabel from '@mui/material/FormControlLabel';\r\nimport './speechComp.css'\r\nimport {useEffect} from \"react\";\r\nimport {useState} from \"react\";\r\nimport {Button, Grid, TextField} from \"@mui/material\";\r\nimport avatar from \"../ressources/avatar.png\";\r\n\r\n\r\nexport const SpeechCom = (props:any) => {\r\n\r\n    const icon = (\r\n        <Paper sx={{ m: 1 }} elevation={4}>\r\n            <Box component=\"svg\" sx={{ width: 100, height: 100 }}>\r\n                <Box\r\n                    component=\"polygon\"\r\n                    sx={{\r\n                        fill: (theme: Theme) => theme.palette.common.white,\r\n                        stroke: (theme) => theme.palette.divider,\r\n                        strokeWidth: 1,\r\n                    }}\r\n                    points=\"0,100 50,00, 100,100\"\r\n                />\r\n            </Box>\r\n        </Paper>\r\n    );\r\n\r\n    const label = (<h1>{props.word}</h1>) ;\r\n\r\n    const [checked, setChecked] = React.useState(false);\r\n    const [show, setShow] = useState(true);\r\n\r\n    const showHide = () => {\r\n        setShow((prev) => !prev);\r\n    }\r\n\r\n    const handleChange = () => {\r\n            setChecked((prev) => !prev);\r\n            setShow((prev) => !prev);\r\n            //setTimeout(showHide, 1000);\r\n    };\r\n\r\n\r\n    const changeAfterSec = async () =>{\r\n        await delay(2000);\r\n    }\r\n\r\n    function delay(time:any) {\r\n        return new Promise(resolve => setTimeout(resolve, time));\r\n    }\r\n\r\n    useEffect(() => {\r\n        console.log('changed',props.word);\r\n        //setChecked((prev) => !prev);\r\n        //handleChange();\r\n        //changeAfterSec();\r\n    },[props.word]);\r\n\r\n    return(\r\n        <>\r\n            <Box className=\"d-flex flex-row justify-content-center align-items-center mt-5\">\r\n                <Grid\r\n                    container\r\n                    spacing={0}\r\n                    direction=\"column\"\r\n                    alignItems=\"center\"\r\n                >\r\n                    {label}\r\n                    <canvas id=\"output\" width=\"400\" height=\"200\"></canvas>\r\n                </Grid>\r\n            </Box>\r\n        </>\r\n    );\r\n};\r\nexport default SpeechCom ;","D:\\Study\\React\\audio-app\\src\\Utils\\methodUtils.js",[],"D:\\Study\\React\\audio-app\\src\\facialRecognition\\authenticate.tsx",["97","98","99","100"],"import * as React from \"react\";\r\nimport FacialRecognition from \"../facialRecognition\";\r\nimport SpeechCom from \"../speechComp/speechComp\";\r\nimport './authenticate.css';\r\nimport Grow from \"@mui/material/Grow/Grow\";\r\nimport Box from \"@mui/material/Box\";\r\nimport {Button, Grid, Paper, TextField} from \"@mui/material\";\r\nimport { Theme } from '@mui/material/styles';\r\nimport {useEffect} from \"react\";\r\nimport avatar from \"../ressources/avatar.png\"\r\n\r\nexport const Authenticate = (props:any) => {\r\n\r\n\r\n    const [checked, setChecked] = React.useState(true);\r\n    const [showAvatar, setShowAvatar] = React.useState(false);\r\n\r\n    const start = () => {\r\n        const facialRecognition = new FacialRecognition();\r\n        facialRecognition.init(setShowAvatar);\r\n    }\r\n\r\n    useEffect(() => {\r\n        start();\r\n    },[]);\r\n\r\n    useEffect(() => {\r\n        console.log('changed',showAvatar);\r\n    },[showAvatar]);\r\n\r\n    return(\r\n        <>\r\n{/*          <div className=\"d-flex flex-row justify-content-center align-items-center\">\r\n                <h1>Authenticate</h1>\r\n                <button onClick={start}>Start</button>\r\n                <div id=\"webcam-container\"></div>\r\n                <div id=\"label-container\"></div>\r\n\r\n            </div>*/}\r\n            <h1 className=\"text-center mt-5\">Login</h1>\r\n            <Box className=\"d-flex flex-row justify-content-center align-items-center mt-5\">\r\n                <Grow\r\n                    in={checked}\r\n                    style={{ transformOrigin: '0 0 0' }}\r\n                    {...(true ? { timeout: 1000 } : {})}\r\n                >\r\n                    <Paper sx={{ width: '30%',height: '600px' }} elevation={4}>\r\n                        <Grid\r\n                            container\r\n                            spacing={0}\r\n                            direction=\"column\"\r\n                            alignItems=\"center\"\r\n                        >\r\n                            {!showAvatar && <div id=\"camera\" className=\"camera mt-5\"></div>}\r\n                            {showAvatar && <img src={avatar} className=\"avatarImage mt-5\"/>}\r\n                            <TextField id=\"outlined-basic\" label=\"Login\" variant=\"outlined\" className=\"mt-5\" />\r\n                            <TextField id=\"outlined-basic\" label=\"Mot de passe\" variant=\"outlined\" className=\"mt-2\"/>\r\n                            <Button variant=\"contained\" className=\"mt-4\">Se connecter</Button>\r\n\r\n                        </Grid>\r\n                    </Paper>\r\n                </Grow>\r\n            </Box>\r\n        </>\r\n    );\r\n\r\n};\r\nexport default Authenticate ;","D:\\Study\\React\\audio-app\\src\\facialRecognition.js",[],"D:\\Study\\React\\audio-app\\src\\speechComp\\speechAction.js",["101","102","103","104"],"import {numberTab, sort, wait} from \"../Utils/methodUtils\";\r\n\r\n\r\nasync function saySpeech (text){\r\n    const voices = window.speechSynthesis.getVoices() ;\r\n    const speechToSay = new window.SpeechSynthesisUtterance(text);\r\n    speechToSay.voice = voices[9];\r\n    window.speechSynthesis.speak(speechToSay);\r\n}\r\n\r\nexport async function wordAction(word) {\r\n\r\n    switch (word.currentWord) {\r\n        case \"Bonjour\": {\r\n            saySpeech(\"Bonjour, comment je peux vous aidez ?\");\r\n            await wait(10000);\r\n            break;\r\n        }\r\n        case \"Consulter\" : {\r\n            saySpeech(\"Merci de me donner le numéros du dossier\");\r\n            await wait(10000);\r\n            break;\r\n        }\r\n        case \"Valider\" : {\r\n            saySpeech(\"Le dossier numéros\" +word.number+ \"est en attente\");\r\n            break;\r\n        }\r\n\r\n            break;\r\n        default : return ;\r\n    }\r\n}\r\n",{"ruleId":"105","replacedBy":"106"},{"ruleId":"107","replacedBy":"108"},{"ruleId":"109","severity":1,"message":"110","line":10,"column":10,"nodeType":"111","messageId":"112","endLine":10,"endColumn":16},{"ruleId":"109","severity":1,"message":"113","line":10,"column":18,"nodeType":"111","messageId":"112","endLine":10,"endColumn":27},{"ruleId":"109","severity":1,"message":"114","line":11,"column":10,"nodeType":"111","messageId":"112","endLine":11,"endColumn":16},{"ruleId":"109","severity":1,"message":"115","line":76,"column":9,"nodeType":"111","messageId":"112","endLine":76,"endColumn":22},{"ruleId":"109","severity":1,"message":"116","line":128,"column":12,"nodeType":"111","messageId":"112","endLine":128,"endColumn":19},{"ruleId":"109","severity":1,"message":"117","line":143,"column":18,"nodeType":"111","messageId":"112","endLine":143,"endColumn":28},{"ruleId":"118","severity":1,"message":"119","line":146,"column":15,"nodeType":"120","messageId":"121","endLine":146,"endColumn":17},{"ruleId":"109","severity":1,"message":"122","line":190,"column":9,"nodeType":"111","messageId":"112","endLine":190,"endColumn":19},{"ruleId":"123","severity":1,"message":"124","line":230,"column":52,"nodeType":"120","messageId":"125","endLine":230,"endColumn":53},{"ruleId":"118","severity":1,"message":"119","line":235,"column":53,"nodeType":"120","messageId":"121","endLine":235,"endColumn":55},{"ruleId":"126","severity":1,"message":"127","line":277,"column":5,"nodeType":"128","endLine":277,"endColumn":7,"suggestions":"129"},{"ruleId":"130","severity":1,"message":"131","line":2,"column":13,"nodeType":"111","messageId":"112","endLine":2,"endColumn":15},{"ruleId":"130","severity":1,"message":"132","line":11,"column":12,"nodeType":"111","messageId":"112","endLine":11,"endColumn":17},{"ruleId":"130","severity":1,"message":"133","line":11,"column":19,"nodeType":"111","messageId":"112","endLine":11,"endColumn":27},{"ruleId":"130","severity":1,"message":"134","line":14,"column":20,"nodeType":"111","messageId":"112","endLine":14,"endColumn":30},{"ruleId":"105","replacedBy":"106"},{"ruleId":"107","replacedBy":"108"},{"ruleId":"135","severity":1,"message":"136","line":4,"column":5,"nodeType":"137","messageId":"138","endLine":4,"endColumn":21},{"ruleId":"130","severity":1,"message":"139","line":1,"column":9,"nodeType":"111","messageId":"112","endLine":1,"endColumn":18},{"ruleId":"130","severity":1,"message":"131","line":2,"column":13,"nodeType":"111","messageId":"112","endLine":2,"endColumn":15},{"ruleId":"130","severity":1,"message":"140","line":3,"column":13,"nodeType":"111","messageId":"112","endLine":3,"endColumn":27},{"ruleId":"130","severity":1,"message":"141","line":5,"column":8,"nodeType":"111","messageId":"112","endLine":5,"endColumn":18},{"ruleId":"130","severity":1,"message":"142","line":6,"column":8,"nodeType":"111","messageId":"112","endLine":6,"endColumn":26},{"ruleId":"130","severity":1,"message":"143","line":7,"column":8,"nodeType":"111","messageId":"112","endLine":7,"endColumn":22},{"ruleId":"130","severity":1,"message":"144","line":4,"column":8,"nodeType":"111","messageId":"112","endLine":4,"endColumn":14},{"ruleId":"130","severity":1,"message":"145","line":6,"column":8,"nodeType":"111","messageId":"112","endLine":6,"endColumn":12},{"ruleId":"130","severity":1,"message":"146","line":7,"column":8,"nodeType":"111","messageId":"112","endLine":7,"endColumn":24},{"ruleId":"130","severity":1,"message":"147","line":11,"column":9,"nodeType":"111","messageId":"112","endLine":11,"endColumn":15},{"ruleId":"130","severity":1,"message":"148","line":11,"column":23,"nodeType":"111","messageId":"112","endLine":11,"endColumn":32},{"ruleId":"130","severity":1,"message":"149","line":12,"column":8,"nodeType":"111","messageId":"112","endLine":12,"endColumn":14},{"ruleId":"130","severity":1,"message":"150","line":17,"column":11,"nodeType":"111","messageId":"112","endLine":17,"endColumn":15},{"ruleId":"130","severity":1,"message":"151","line":35,"column":12,"nodeType":"111","messageId":"112","endLine":35,"endColumn":19},{"ruleId":"130","severity":1,"message":"152","line":36,"column":12,"nodeType":"111","messageId":"112","endLine":36,"endColumn":16},{"ruleId":"130","severity":1,"message":"153","line":38,"column":11,"nodeType":"111","messageId":"112","endLine":38,"endColumn":19},{"ruleId":"130","severity":1,"message":"154","line":42,"column":11,"nodeType":"111","messageId":"112","endLine":42,"endColumn":23},{"ruleId":"130","severity":1,"message":"155","line":49,"column":11,"nodeType":"111","messageId":"112","endLine":49,"endColumn":25},{"ruleId":"130","severity":1,"message":"156","line":3,"column":8,"nodeType":"111","messageId":"112","endLine":3,"endColumn":17},{"ruleId":"130","severity":1,"message":"157","line":8,"column":10,"nodeType":"111","messageId":"112","endLine":8,"endColumn":15},{"ruleId":"130","severity":1,"message":"158","line":15,"column":21,"nodeType":"111","messageId":"112","endLine":15,"endColumn":31},{"ruleId":"159","severity":1,"message":"160","line":55,"column":44,"nodeType":"161","endLine":55,"endColumn":92},{"ruleId":"109","severity":1,"message":"162","line":1,"column":9,"nodeType":"111","messageId":"112","endLine":1,"endColumn":18},{"ruleId":"109","severity":1,"message":"163","line":1,"column":20,"nodeType":"111","messageId":"112","endLine":1,"endColumn":24},{"ruleId":"164","severity":1,"message":"165","line":24,"column":26,"nodeType":"166","messageId":"167","endLine":27,"endColumn":10},{"ruleId":"168","severity":1,"message":"169","line":29,"column":13,"nodeType":"170","messageId":"171","endLine":29,"endColumn":19},"no-native-reassign",["172"],"no-negated-in-lhs",["173"],"no-unused-vars","'action' is assigned a value but never used.","Identifier","unusedVar","'setAction' is assigned a value but never used.","'labels' is assigned a value but never used.","'setStateAsync' is assigned a value but never used.","'predict' is defined but never used.","'moveSlider' is defined but never used.","eqeqeq","Expected '===' and instead saw '=='.","BinaryExpression","unexpected","'testListen' is assigned a value but never used.","no-useless-concat","Unexpected string concatenation of literals.","unexpectedConcat","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'buildModel' and 'modelTobuild'. Either include them or remove the dependency array.","ArrayExpression",["174"],"@typescript-eslint/no-unused-vars","'tf' is defined but never used.","'model' is assigned a value but never used.","'setModel' is assigned a value but never used.","'buildModel' is defined but never used.","no-useless-constructor","Useless constructor.","MethodDefinition","noUselessConstructor","'useEffect' is defined but never used.","'SpeechCommands' is defined but never used.","'VoiceModel' is defined but never used.","'VoiceModelMetadata' is defined but never used.","'VoiceAssistant' is defined but never used.","'Switch' is defined but never used.","'Grow' is defined but never used.","'FormControlLabel' is defined but never used.","'Button' is defined but never used.","'TextField' is defined but never used.","'avatar' is defined but never used.","'icon' is assigned a value but never used.","'checked' is assigned a value but never used.","'show' is assigned a value but never used.","'showHide' is assigned a value but never used.","'handleChange' is assigned a value but never used.","'changeAfterSec' is assigned a value but never used.","'SpeechCom' is defined but never used.","'Theme' is defined but never used.","'setChecked' is assigned a value but never used.","jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","JSXOpeningElement","'numberTab' is defined but never used.","'sort' is defined but never used.","no-lone-blocks","Block is redundant.","BlockStatement","redundantBlock","no-unreachable","Unreachable code.","BreakStatement","unreachableCode","no-global-assign","no-unsafe-negation",{"desc":"175","fix":"176"},"Update the dependencies array to be: [buildModel, modelTobuild]",{"range":"177","text":"178"},[8321,8323],"[buildModel, modelTobuild]"]
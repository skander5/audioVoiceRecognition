[{"D:\\Study\\React\\audio-app\\src\\index.js":"1","D:\\Study\\React\\audio-app\\src\\reportWebVitals.js":"2","D:\\Study\\React\\audio-app\\src\\App.js":"3","D:\\Study\\React\\audio-app\\src\\home.tsx":"4","D:\\Study\\React\\audio-app\\src\\voiceAssistant.js":"5","D:\\Study\\React\\audio-app\\src\\voiceVisualizer.js":"6","D:\\Study\\React\\audio-app\\src\\listening\\listening.tsx":"7","D:\\Study\\React\\audio-app\\src\\speechComp\\speechComp.tsx":"8","D:\\Study\\React\\audio-app\\src\\Utils\\methodUtils.js":"9","D:\\Study\\React\\audio-app\\src\\facialRecognition\\authenticate.tsx":"10","D:\\Study\\React\\audio-app\\src\\facialRecognition.js":"11"},{"size":981,"mtime":1653068489509,"results":"12","hashOfConfig":"13"},{"size":362,"mtime":499162500000,"results":"14","hashOfConfig":"13"},{"size":10377,"mtime":1649847735166,"results":"15","hashOfConfig":"13"},{"size":1166,"mtime":1649803028668,"results":"16","hashOfConfig":"13"},{"size":5183,"mtime":1652855762263,"results":"17","hashOfConfig":"13"},{"size":792,"mtime":1650705415507,"results":"18","hashOfConfig":"13"},{"size":1855,"mtime":1653637477331,"results":"19","hashOfConfig":"13"},{"size":2607,"mtime":1652989126318,"results":"20","hashOfConfig":"13"},{"size":390,"mtime":1650741216650,"results":"21","hashOfConfig":"13"},{"size":2585,"mtime":1653637437374,"results":"22","hashOfConfig":"13"},{"size":2354,"mtime":1653636213962,"results":"23","hashOfConfig":"13"},{"filePath":"24","messages":"25","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},"utvmey",{"filePath":"27","messages":"28","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"29","messages":"30","errorCount":0,"fatalErrorCount":0,"warningCount":11,"fixableErrorCount":0,"fixableWarningCount":0,"source":"31","usedDeprecatedRules":"26"},{"filePath":"32","messages":"33","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"34","usedDeprecatedRules":"35"},{"filePath":"36","messages":"37","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"38","messages":"39","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"40","usedDeprecatedRules":"26"},{"filePath":"41","messages":"42","errorCount":0,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"43","messages":"44","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"45","usedDeprecatedRules":"35"},{"filePath":"46","messages":"47","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"48","messages":"49","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"50","messages":"51","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"D:\\Study\\React\\audio-app\\src\\index.js",[],["52","53"],"D:\\Study\\React\\audio-app\\src\\reportWebVitals.js",[],"D:\\Study\\React\\audio-app\\src\\App.js",["54","55","56","57","58","59","60","61","62","63","64"],"import logo from './logo.svg';\nimport './App.css';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as speech from \"@tensorflow-models/speech-commands\"\nimport {useEffect, useState} from \"react\";\n\nfunction App() {\n\n  const [model, setModel] = useState(null);\n  const [action, setAction] = useState(null);\n  const [labels, setLabels] = useState(null);\n  const [modelTobuilded,setModelTobuilded] = useState(null);\n\n  const NUM_FRAMES = 3;\n  const INPUT_SHAPE = [NUM_FRAMES, 232, 1];\n  let examples = [];\n  let modelTobuild ;\n\n  const loadModel = async () => {\n    const recognizer = await speech.create('BROWSER_FFT');\n    console.log(\"Model Loaded\");\n    await recognizer.ensureModelLoaded();\n    setModel(recognizer);\n    setLabels(recognizer.words);\n    console.log(\"fffffd \",recognizer);\n  }\n\n  const recognizeCommands = async () =>{\n    console.log('Listening for commands')\n    model.listen(result=>{\n      console.log(Object.values(result.scores));\n      let scores = Array.from(result.scores).map((s, i) => ({score: s, word: model.words[i]}));\n      scores.sort((s1, s2) => s2.score - s1.score);\n      console.log('scores ',scores[0]);\n    }, {includeSpectrogram:true, probabilityThreshold:0.9});\n  };\n\n  const train = async () => {\n    console.log(examples);\n    const ys = tf.oneHot(examples.map(e => e.label), 3);\n    const xsShape = [examples.length, ...INPUT_SHAPE];\n    const xs = tf.tensor(flatten(examples.map(e => e.vals)), xsShape);\n    await modelTobuilded.fit(xs, ys, {\n      batchSize: 16,\n      epochs: 100,\n      callbacks: {\n        onEpochEnd: (epoch, logs) => {\n          console.log(\n              `Accuracy: ${(logs.acc * 100).toFixed(1)}% Epoch: ${epoch + 1}`);\n        }\n      }\n    });\n    tf.dispose([xs, ys]);\n  };\n\n  async function buildModel() {\n    modelTobuild = tf.sequential();\n    modelTobuild.add(tf.layers.depthwiseConv2d({\n      depthMultiplier: 8,\n      kernelSize: [NUM_FRAMES, 3],\n      activation: 'relu',\n      inputShape: INPUT_SHAPE\n    }));\n    modelTobuild.add(tf.layers.maxPooling2d({poolSize: [1, 2], strides: [2, 2]}));\n    modelTobuild.add(tf.layers.flatten());\n    modelTobuild.add(tf.layers.dense({units: 3, activation: 'softmax'}));\n    const optimizer = tf.train.adam(0.01);\n    modelTobuild.compile({\n      optimizer,\n      loss: 'categoricalCrossentropy',\n      metrics: ['accuracy']\n    });\n    setModelTobuilded(modelTobuild);\n  }\n\n  const setStateAsync = (state) => {\n    return new Promise((resolve) => {\n      this.setState(state, resolve)\n    });\n  }\n\n  function flatten(tensors) {\n    const size = tensors[0].length;\n    const result = new Float32Array(tensors.length * size);\n    tensors.forEach((arr, i) => result.set(arr, i * size));\n    return result;\n  }\n\n  const collectVoice = (label) => {\n    if(model != null) {\n      if (model.isListening()) {\n        return model.stopListening();\n      }\n      if (label == null) {\n        console.log(label);\n        return;\n      }\n      model.listen(async ({spectrogram: {frameSize, data}}) => {\n        console.log('fr : ', frameSize,\" da : \",data.subarray()[0], \" r : \",Math.round(data.subarray()[0] * 100) / 100);\n        if (data.subarray()[0] !== 0) {\n          //let result = [] ;\n          //for(var i in JSON.stringify(data))\n          //console.log(\"i : \",JSON.stringify(data) [i]);\n          //result.push([i, JSON.stringify(data) [i]]);\n\n          let vals = normalize(data.subarray(-frameSize * NUM_FRAMES));\n          //console.log(data.subarray());\n          //for(var i in vals)\n            //console.log(vals[i]);\n          examples.push({vals, label});\n          console.log(`${examples.length}`, \" examples for \", label);\n        }\n      }, {\n        overlapFactor: 0.5,\n        includeSpectrogram: true,\n        invokeCallbackOnNoiseAndUnknown: true\n      });\n      console.log(examples);\n    }\n  }\n\n  function normalize(x) {\n    const mean = -100;\n    const std = 10;\n    return x.map(x => (x - mean) / std);\n  }\n\n  function predict(){\n    let scores = Array.from(examples).map((s, i) => ({val: s, label: i}));\n    scores.sort((s1, s2) => s2.val - s1.val);\n    console.log(scores[0]);\n  }\n\n  function saveExemple(){\n    const element = document.createElement(\"a\");\n    const file = new Blob([JSON.stringify(examples)], {type: 'text/plain'});\n    element.href = URL.createObjectURL(file);\n    element.download = \"myFile.txt\";\n    document.body.appendChild(element);\n    element.click();\n  }\n\n  async function moveSlider(labelTensor) {\n    const label = (await labelTensor.data())[0];\n    console.log(label);\n    if (label == 2) {\n      return;\n    }\n    let delta = 0.1;\n    const prevValue = +document.getElementById('output').value;\n    document.getElementById('output').value =\n        prevValue + (label === 0 ? -delta : delta);\n  }\n\n  const listen = () => {\n    if (model.isListening()) {\n      model.stopListening();\n      console.log('Listen');\n      return;\n    }\n    console.log('Stop');\n\n    model.listen(async ({spectrogram: {frameSize, data}}) => {\n\n      const vals = normalize(data.subarray(-frameSize * NUM_FRAMES));\n      const input = tf.tensor(vals, [1, ...INPUT_SHAPE]);\n      const probs = modelTobuilded.predict(input);\n      const predLabel = probs.argMax(1);\n      const scores = probs.arraySync()[0];\n\n      console.log(scores);\n      const score = Array.from(scores).map((s, i) => ({score: s, word: i}));\n      score.sort((s1, s2) => s2.score - s1.score);\n      console.log(score[0].word);\n\n      //console.log('prelabel ',predLabel);\n      const labela = (await predLabel.data())[0];\n      console.log(labela);\n      //await moveSlider(predLabel);\n\n      tf.dispose([input, probs, predLabel]);\n    }, {\n      overlapFactor: 0.5,\n      includeSpectrogram: true,\n      invokeCallbackOnNoiseAndUnknown: true,\n      probabilityThershold: 0.8,\n    });\n  };\n\n  const testListen = async () => {\n    const baseRecognizer = await speech.create('BROWSER_FFT');\n    await baseRecognizer.ensureModelLoaded();\n    const transferRecognizer = baseRecognizer.createTransfer('colors');\n\n    await transferRecognizer.collectExample('red');\n    await transferRecognizer.collectExample('green');\n    await transferRecognizer.collectExample('blue');\n    await transferRecognizer.collectExample('red');\n\n    await transferRecognizer.collectExample('_background_noise_');\n    await transferRecognizer.collectExample('green');\n    await transferRecognizer.collectExample('blue');\n    await transferRecognizer.collectExample('_background_noise_');\n\n    console.log(transferRecognizer.countExamples());\n\n    await transferRecognizer.train({\n      epochs: 25,\n      callback: {\n        onEpochEnd: async (epoch, logs) => {\n          console.log(`Epoch ${epoch}: loss=${logs.loss}, accuracy=${logs.acc}`);\n        }\n      }\n    });\n\n    await transferRecognizer.listen(result => {\n\n      const words = transferRecognizer.wordLabels();\n\n      for (let i = 0; i < words; ++i) {\n        console.log(`score for word '${words[i]}' = ${result.scores[i]}`);\n      }\n    }, {probabilityThreshold: 0.75});\n\n    setTimeout(() => transferRecognizer.stopListening(), 10e3);\n  }\n\n  const exportFile = () => {\n    var rawFile = new XMLHttpRequest();\n    rawFile.open(\"GET\", `${window.location.origin}`+'\\\\myFile.txt', false);\n    rawFile.onreadystatechange = function ()\n    {\n      if(rawFile.readyState === 4)\n      {\n        if(rawFile.status === 200 || rawFile.status == 0)\n        {\n          var allText = rawFile.responseText;\n          examples = allText ;\n          console.log(allText);\n        }\n      }\n    }\n    rawFile.send(null);\n  }\n\n  const cleanData = () => {\n    let voir = examples.filter(e => e.label === 1);\n    console.log(voir.length);\n    let noise = examples.filter(e => e.label === 0);\n    console.log(voir[0].vals.json);\n    for(var i in voir)\n      for(var j of voir[i].vals){\n\n        console.log(j);\n      }\n    voir.forEach(e => {\n      //let index = noise.val.indexOf(e.val) ;\n      //console.log(e.vals);\n      noise.forEach(r => {\n        if(e.val === r.val){\n          //voir.splice(voir.indexOf(e),1);\n        }\n      });\n      //if(index !== -1) {\n        //voir.splice(voir.indexOf(e),1);\n      //}\n    });\n    console.log(voir.length);\n    console.log(noise.length);\n\n  };\n\n  useEffect(() => {\n    loadModel();\n    buildModel();\n    console.log(modelTobuild);\n  },[]);\n\n\n  return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n          <img src={logo} className=\"App-logo\" alt=\"logo\" />\n          <p>\n            Edit <code>src/App.js</code> and save to reload.\n          </p>\n          <button onClick={recognizeCommands}>Listening</button>\n          <button onMouseDown={() => collectVoice(0)} onMouseUp={() => collectVoice(0)}>SILENCE</button>\n          <button onMouseDown={() => collectVoice(1)} onMouseUp={() => collectVoice(1)}>ZERO</button>\n          <button onMouseDown={() => collectVoice(2)} onMouseUp={() => collectVoice(2)}>ONE</button>\n          <button onMouseDown={() => collectVoice(4)} onMouseUp={() => collectVoice(4)}>TWO</button>\n          <button onMouseDown={() => collectVoice(5)} onMouseUp={() => collectVoice(5)}>THREE</button>\n          <button onMouseDown={() => collectVoice(6)} onMouseUp={() => collectVoice(6)}>FOUR</button>\n          <button onMouseDown={() => collectVoice(7)} onMouseUp={() => collectVoice(7)}>FIVE</button>\n          <button onMouseDown={() => collectVoice(8)} onMouseUp={() => collectVoice(8)}>SIX</button>\n          <button onMouseDown={() => collectVoice(9)} onMouseUp={() => collectVoice(9)}>SEVEN</button>\n          <button onMouseDown={() => collectVoice(10)} onMouseUp={() => collectVoice(10)}>EIGHT</button>\n          <button onMouseDown={() => collectVoice(11)} onMouseUp={() => collectVoice(11)}>NINE</button>\n          <button onMouseDown={() => collectVoice(1)} onMouseUp={() => collectVoice(1)}>NOISE</button>\n\n\n          <button onClick={train}>Train</button>\n          <input type=\"range\" id=\"output\" min=\"0\" max=\"10\" step=\"0.1\"/>\n          <button onClick={listen}>Listen</button>\n          <button onClick={saveExemple}>save</button>\n          <button onClick={()=>model.stopListening()}>Stop</button>\n          <button onClick={saveExemple}>save</button>\n          <button onClick={exportFile}>export</button>\n          <button onClick={cleanData}>showList</button>\n\n        </header>\n\n      </div>\n  );\n}\n\nexport default App;\n","D:\\Study\\React\\audio-app\\src\\home.tsx",["65","66","67","68"],"import {useEffect, useState} from \"react\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\nimport * as SpeechCommands from \"@tensorflow-models/speech-commands\";\r\n\r\nimport VoiceModel from \"./My_Model/model.json\";\r\nimport VoiceModelMetadata from \"./My_Model/metadata.json\";\r\nimport VoiceAssistant from \"./voiceAssistant\";\r\n\r\nexport const HomePage = () => {\r\n\r\n    const [model, setModel] = useState(null);\r\n    let voiceAssistant;\r\n\r\n    async function buildModel() {\r\n        const recognizer = await SpeechCommands.create(\"BROWSER_FFT\",undefined,VoiceModel,VoiceModelMetadata);\r\n        await recognizer.ensureModelLoaded();\r\n        console.log(\"Model Loaded\");\r\n        return recognizer;\r\n    }\r\n\r\n    const startAssistance = async () => {\r\n        //const recognizer = await buildModel();\r\n        voiceAssistant = new VoiceAssistant();\r\n        voiceAssistant.start();\r\n        //recognizer.listen((result)=>{},null);\r\n    }\r\n\r\n    useEffect(()=> {\r\n        console.log('ooooo');\r\n    },[]);\r\n\r\n    return (\r\n        <div>\r\n            <h1>OK</h1>\r\n            <button onClick={startAssistance} >Start</button>\r\n        </div>\r\n    );\r\n\r\n};\r\nexport default HomePage ;",["69","70"],"D:\\Study\\React\\audio-app\\src\\voiceAssistant.js",[],"D:\\Study\\React\\audio-app\\src\\voiceVisualizer.js",["71"],"import Wave from \"wave-visualizer\";\r\n\r\nexport default class VoiceVisualizer {\r\n    constructor() {}\r\n\r\n    async openAudioStream() {\r\n        try {\r\n            this.audioStream = await navigator.mediaDevices.getUserMedia({\r\n                audio: true,\r\n            });\r\n        } catch (err) {\r\n            console.error(\"Cannot open Audio Stream \", err);\r\n        }\r\n    }\r\n\r\n    async startVisualization() {\r\n        await this.openAudioStream();\r\n\r\n        let wave = new Wave();\r\n\r\n        wave.fromStream(this.audioStream, \"output\", {\r\n            type: \"bars\",\r\n            colors: [\"white\", \"FFFFFF\"],\r\n            stroke: 1,\r\n        });\r\n    }\r\n\r\n    stopVisualization() {\r\n        this.audioStream.getTracks().forEach((track) => {\r\n            track.stop();\r\n        });\r\n    }\r\n}","D:\\Study\\React\\audio-app\\src\\listening\\listening.tsx",["72","73","74","75","76","77","78"],"D:\\Study\\React\\audio-app\\src\\speechComp\\speechComp.tsx",["79","80","81"],"import * as React from 'react';\r\nimport { Theme } from '@mui/material/styles';\r\nimport Box from '@mui/material/Box';\r\nimport Switch from '@mui/material/Switch';\r\nimport Paper from '@mui/material/Paper';\r\nimport Grow from '@mui/material/Grow';\r\nimport FormControlLabel from '@mui/material/FormControlLabel';\r\nimport './speechComp.css'\r\nimport {useEffect} from \"react\";\r\nimport {useState} from \"react\";\r\n\r\n\r\nexport const SpeechCom = (props:any) => {\r\n\r\n    const icon = (\r\n        <Paper sx={{ m: 1 }} elevation={4}>\r\n            <Box component=\"svg\" sx={{ width: 100, height: 100 }}>\r\n                <Box\r\n                    component=\"polygon\"\r\n                    sx={{\r\n                        fill: (theme: Theme) => theme.palette.common.white,\r\n                        stroke: (theme) => theme.palette.divider,\r\n                        strokeWidth: 1,\r\n                    }}\r\n                    points=\"0,100 50,00, 100,100\"\r\n                />\r\n            </Box>\r\n        </Paper>\r\n    );\r\n\r\n    const label = (<h1>{props.word}</h1>) ;\r\n\r\n    const [checked, setChecked] = React.useState(false);\r\n    const [show, setShow] = useState(true);\r\n\r\n    const showHide = () => {\r\n        setShow((prev) => !prev);\r\n    }\r\n\r\n    const handleChange = () => {\r\n            setChecked((prev) => !prev);\r\n            setShow((prev) => !prev);\r\n            //setTimeout(showHide, 1000);\r\n    };\r\n\r\n\r\n    const changeAfterSec = async () =>{\r\n        await delay(2000);\r\n    }\r\n\r\n    function delay(time:any) {\r\n        return new Promise(resolve => setTimeout(resolve, time));\r\n    }\r\n\r\n    useEffect(() => {\r\n        console.log('changed',props.word);\r\n        //setChecked((prev) => !prev);\r\n        //handleChange();\r\n        //changeAfterSec();\r\n    },[props.word]);\r\n\r\n    return(\r\n        <>\r\n            <Box sx={{ display: 'flex',justifyContent: 'center',flexDirection:'column',ml:67}}>\r\n                <Box>\r\n                    <FormControlLabel\r\n                        control={<Switch checked={checked} onChange={handleChange} />}\r\n                        label=\"Show\"\r\n                    />\r\n                </Box>\r\n                <Box>\r\n                    <Grow in={show} style={{ transformOrigin: '0 0 0' }} {...(show ? { timeout: 1000 } : {})}>\r\n                        {label}\r\n                    </Grow>\r\n                </Box>\r\n            </Box>\r\n            <Box id=\"visualizer-container\" sx={{ display: 'flex',justifyContent: 'center'}}>\r\n                <canvas id=\"output\" width=\"400\" height=\"200\"></canvas>\r\n            </Box>\r\n        </>\r\n    );\r\n};\r\nexport default SpeechCom ;","D:\\Study\\React\\audio-app\\src\\Utils\\methodUtils.js",[],"D:\\Study\\React\\audio-app\\src\\facialRecognition\\authenticate.tsx",["82","83","84","85"],"D:\\Study\\React\\audio-app\\src\\facialRecognition.js",[],{"ruleId":"86","replacedBy":"87"},{"ruleId":"88","replacedBy":"89"},{"ruleId":"90","severity":1,"message":"91","line":10,"column":10,"nodeType":"92","messageId":"93","endLine":10,"endColumn":16},{"ruleId":"90","severity":1,"message":"94","line":10,"column":18,"nodeType":"92","messageId":"93","endLine":10,"endColumn":27},{"ruleId":"90","severity":1,"message":"95","line":11,"column":10,"nodeType":"92","messageId":"93","endLine":11,"endColumn":16},{"ruleId":"90","severity":1,"message":"96","line":76,"column":9,"nodeType":"92","messageId":"93","endLine":76,"endColumn":22},{"ruleId":"90","severity":1,"message":"97","line":128,"column":12,"nodeType":"92","messageId":"93","endLine":128,"endColumn":19},{"ruleId":"90","severity":1,"message":"98","line":143,"column":18,"nodeType":"92","messageId":"93","endLine":143,"endColumn":28},{"ruleId":"99","severity":1,"message":"100","line":146,"column":15,"nodeType":"101","messageId":"102","endLine":146,"endColumn":17},{"ruleId":"90","severity":1,"message":"103","line":190,"column":9,"nodeType":"92","messageId":"93","endLine":190,"endColumn":19},{"ruleId":"104","severity":1,"message":"105","line":230,"column":52,"nodeType":"101","messageId":"106","endLine":230,"endColumn":53},{"ruleId":"99","severity":1,"message":"100","line":235,"column":53,"nodeType":"101","messageId":"102","endLine":235,"endColumn":55},{"ruleId":"107","severity":1,"message":"108","line":277,"column":5,"nodeType":"109","endLine":277,"endColumn":7,"suggestions":"110"},{"ruleId":"111","severity":1,"message":"112","line":2,"column":13,"nodeType":"92","messageId":"93","endLine":2,"endColumn":15},{"ruleId":"111","severity":1,"message":"113","line":11,"column":12,"nodeType":"92","messageId":"93","endLine":11,"endColumn":17},{"ruleId":"111","severity":1,"message":"114","line":11,"column":19,"nodeType":"92","messageId":"93","endLine":11,"endColumn":27},{"ruleId":"111","severity":1,"message":"115","line":14,"column":20,"nodeType":"92","messageId":"93","endLine":14,"endColumn":30},{"ruleId":"86","replacedBy":"87"},{"ruleId":"88","replacedBy":"89"},{"ruleId":"116","severity":1,"message":"117","line":4,"column":5,"nodeType":"118","messageId":"119","endLine":4,"endColumn":21},{"ruleId":"111","severity":1,"message":"120","line":1,"column":9,"nodeType":"92","messageId":"93","endLine":1,"endColumn":18},{"ruleId":"111","severity":1,"message":"112","line":2,"column":13,"nodeType":"92","messageId":"93","endLine":2,"endColumn":15},{"ruleId":"111","severity":1,"message":"121","line":3,"column":13,"nodeType":"92","messageId":"93","endLine":3,"endColumn":27},{"ruleId":"111","severity":1,"message":"122","line":5,"column":8,"nodeType":"92","messageId":"93","endLine":5,"endColumn":18},{"ruleId":"111","severity":1,"message":"123","line":6,"column":8,"nodeType":"92","messageId":"93","endLine":6,"endColumn":26},{"ruleId":"111","severity":1,"message":"124","line":7,"column":8,"nodeType":"92","messageId":"93","endLine":7,"endColumn":22},{"ruleId":"111","severity":1,"message":"125","line":22,"column":9,"nodeType":"92","messageId":"93","endLine":22,"endColumn":23},{"ruleId":"111","severity":1,"message":"126","line":15,"column":11,"nodeType":"92","messageId":"93","endLine":15,"endColumn":15},{"ruleId":"111","severity":1,"message":"127","line":36,"column":11,"nodeType":"92","messageId":"93","endLine":36,"endColumn":19},{"ruleId":"111","severity":1,"message":"128","line":47,"column":11,"nodeType":"92","messageId":"93","endLine":47,"endColumn":25},{"ruleId":"111","severity":1,"message":"129","line":3,"column":8,"nodeType":"92","messageId":"93","endLine":3,"endColumn":17},{"ruleId":"111","severity":1,"message":"130","line":8,"column":10,"nodeType":"92","messageId":"93","endLine":8,"endColumn":15},{"ruleId":"111","severity":1,"message":"131","line":15,"column":21,"nodeType":"92","messageId":"93","endLine":15,"endColumn":31},{"ruleId":"132","severity":1,"message":"133","line":55,"column":44,"nodeType":"134","endLine":55,"endColumn":92},"no-native-reassign",["135"],"no-negated-in-lhs",["136"],"no-unused-vars","'action' is assigned a value but never used.","Identifier","unusedVar","'setAction' is assigned a value but never used.","'labels' is assigned a value but never used.","'setStateAsync' is assigned a value but never used.","'predict' is defined but never used.","'moveSlider' is defined but never used.","eqeqeq","Expected '===' and instead saw '=='.","BinaryExpression","unexpected","'testListen' is assigned a value but never used.","no-useless-concat","Unexpected string concatenation of literals.","unexpectedConcat","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'buildModel' and 'modelTobuild'. Either include them or remove the dependency array.","ArrayExpression",["137"],"@typescript-eslint/no-unused-vars","'tf' is defined but never used.","'model' is assigned a value but never used.","'setModel' is assigned a value but never used.","'buildModel' is defined but never used.","no-useless-constructor","Useless constructor.","MethodDefinition","noUselessConstructor","'useEffect' is defined but never used.","'SpeechCommands' is defined but never used.","'VoiceModel' is defined but never used.","'VoiceModelMetadata' is defined but never used.","'VoiceAssistant' is defined but never used.","'processingWord' is assigned a value but never used.","'icon' is assigned a value but never used.","'showHide' is assigned a value but never used.","'changeAfterSec' is assigned a value but never used.","'SpeechCom' is defined but never used.","'Theme' is defined but never used.","'setChecked' is assigned a value but never used.","jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","JSXOpeningElement","no-global-assign","no-unsafe-negation",{"desc":"138","fix":"139"},"Update the dependencies array to be: [buildModel, modelTobuild]",{"range":"140","text":"141"},[8321,8323],"[buildModel, modelTobuild]"]
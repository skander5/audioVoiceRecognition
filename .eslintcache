[{"D:\\Study\\React\\audio-app\\src\\index.js":"1","D:\\Study\\React\\audio-app\\src\\reportWebVitals.js":"2","D:\\Study\\React\\audio-app\\src\\App.js":"3","D:\\Study\\React\\audio-app\\src\\home.tsx":"4","D:\\Study\\React\\audio-app\\src\\voiceAssistant.js":"5","D:\\Study\\React\\audio-app\\src\\voiceVisualizer.js":"6","D:\\Study\\React\\audio-app\\src\\listening\\listening.tsx":"7","D:\\Study\\React\\audio-app\\src\\speechComp\\speechComp.tsx":"8","D:\\Study\\React\\audio-app\\src\\Utils\\methodUtils.js":"9"},{"size":842,"mtime":1650706274783,"results":"10","hashOfConfig":"11"},{"size":362,"mtime":499162500000,"results":"12","hashOfConfig":"11"},{"size":10377,"mtime":1649847735166,"results":"13","hashOfConfig":"11"},{"size":1166,"mtime":1649803028668,"results":"14","hashOfConfig":"11"},{"size":3809,"mtime":1650740612192,"results":"15","hashOfConfig":"11"},{"size":792,"mtime":1650705415507,"results":"16","hashOfConfig":"11"},{"size":1450,"mtime":1650741238370,"results":"17","hashOfConfig":"11"},{"size":2070,"mtime":1650740340236,"results":"18","hashOfConfig":"11"},{"size":390,"mtime":1650741216650,"results":"19","hashOfConfig":"11"},{"filePath":"20","messages":"21","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"22"},"utvmey",{"filePath":"23","messages":"24","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"22"},{"filePath":"25","messages":"26","errorCount":0,"fatalErrorCount":0,"warningCount":11,"fixableErrorCount":0,"fixableWarningCount":0,"source":"27","usedDeprecatedRules":"22"},{"filePath":"28","messages":"29","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"30","usedDeprecatedRules":"31"},{"filePath":"32","messages":"33","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"34","messages":"35","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"36","usedDeprecatedRules":"22"},{"filePath":"37","messages":"38","errorCount":0,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"39","messages":"40","errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"41","messages":"42","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"D:\\Study\\React\\audio-app\\src\\index.js",[],["43","44"],"D:\\Study\\React\\audio-app\\src\\reportWebVitals.js",[],"D:\\Study\\React\\audio-app\\src\\App.js",["45","46","47","48","49","50","51","52","53","54","55"],"import logo from './logo.svg';\nimport './App.css';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as speech from \"@tensorflow-models/speech-commands\"\nimport {useEffect, useState} from \"react\";\n\nfunction App() {\n\n  const [model, setModel] = useState(null);\n  const [action, setAction] = useState(null);\n  const [labels, setLabels] = useState(null);\n  const [modelTobuilded,setModelTobuilded] = useState(null);\n\n  const NUM_FRAMES = 3;\n  const INPUT_SHAPE = [NUM_FRAMES, 232, 1];\n  let examples = [];\n  let modelTobuild ;\n\n  const loadModel = async () => {\n    const recognizer = await speech.create('BROWSER_FFT');\n    console.log(\"Model Loaded\");\n    await recognizer.ensureModelLoaded();\n    setModel(recognizer);\n    setLabels(recognizer.words);\n    console.log(\"fffffd \",recognizer);\n  }\n\n  const recognizeCommands = async () =>{\n    console.log('Listening for commands')\n    model.listen(result=>{\n      console.log(Object.values(result.scores));\n      let scores = Array.from(result.scores).map((s, i) => ({score: s, word: model.words[i]}));\n      scores.sort((s1, s2) => s2.score - s1.score);\n      console.log('scores ',scores[0]);\n    }, {includeSpectrogram:true, probabilityThreshold:0.9});\n  };\n\n  const train = async () => {\n    console.log(examples);\n    const ys = tf.oneHot(examples.map(e => e.label), 3);\n    const xsShape = [examples.length, ...INPUT_SHAPE];\n    const xs = tf.tensor(flatten(examples.map(e => e.vals)), xsShape);\n    await modelTobuilded.fit(xs, ys, {\n      batchSize: 16,\n      epochs: 100,\n      callbacks: {\n        onEpochEnd: (epoch, logs) => {\n          console.log(\n              `Accuracy: ${(logs.acc * 100).toFixed(1)}% Epoch: ${epoch + 1}`);\n        }\n      }\n    });\n    tf.dispose([xs, ys]);\n  };\n\n  async function buildModel() {\n    modelTobuild = tf.sequential();\n    modelTobuild.add(tf.layers.depthwiseConv2d({\n      depthMultiplier: 8,\n      kernelSize: [NUM_FRAMES, 3],\n      activation: 'relu',\n      inputShape: INPUT_SHAPE\n    }));\n    modelTobuild.add(tf.layers.maxPooling2d({poolSize: [1, 2], strides: [2, 2]}));\n    modelTobuild.add(tf.layers.flatten());\n    modelTobuild.add(tf.layers.dense({units: 3, activation: 'softmax'}));\n    const optimizer = tf.train.adam(0.01);\n    modelTobuild.compile({\n      optimizer,\n      loss: 'categoricalCrossentropy',\n      metrics: ['accuracy']\n    });\n    setModelTobuilded(modelTobuild);\n  }\n\n  const setStateAsync = (state) => {\n    return new Promise((resolve) => {\n      this.setState(state, resolve)\n    });\n  }\n\n  function flatten(tensors) {\n    const size = tensors[0].length;\n    const result = new Float32Array(tensors.length * size);\n    tensors.forEach((arr, i) => result.set(arr, i * size));\n    return result;\n  }\n\n  const collectVoice = (label) => {\n    if(model != null) {\n      if (model.isListening()) {\n        return model.stopListening();\n      }\n      if (label == null) {\n        console.log(label);\n        return;\n      }\n      model.listen(async ({spectrogram: {frameSize, data}}) => {\n        console.log('fr : ', frameSize,\" da : \",data.subarray()[0], \" r : \",Math.round(data.subarray()[0] * 100) / 100);\n        if (data.subarray()[0] !== 0) {\n          //let result = [] ;\n          //for(var i in JSON.stringify(data))\n          //console.log(\"i : \",JSON.stringify(data) [i]);\n          //result.push([i, JSON.stringify(data) [i]]);\n\n          let vals = normalize(data.subarray(-frameSize * NUM_FRAMES));\n          //console.log(data.subarray());\n          //for(var i in vals)\n            //console.log(vals[i]);\n          examples.push({vals, label});\n          console.log(`${examples.length}`, \" examples for \", label);\n        }\n      }, {\n        overlapFactor: 0.5,\n        includeSpectrogram: true,\n        invokeCallbackOnNoiseAndUnknown: true\n      });\n      console.log(examples);\n    }\n  }\n\n  function normalize(x) {\n    const mean = -100;\n    const std = 10;\n    return x.map(x => (x - mean) / std);\n  }\n\n  function predict(){\n    let scores = Array.from(examples).map((s, i) => ({val: s, label: i}));\n    scores.sort((s1, s2) => s2.val - s1.val);\n    console.log(scores[0]);\n  }\n\n  function saveExemple(){\n    const element = document.createElement(\"a\");\n    const file = new Blob([JSON.stringify(examples)], {type: 'text/plain'});\n    element.href = URL.createObjectURL(file);\n    element.download = \"myFile.txt\";\n    document.body.appendChild(element);\n    element.click();\n  }\n\n  async function moveSlider(labelTensor) {\n    const label = (await labelTensor.data())[0];\n    console.log(label);\n    if (label == 2) {\n      return;\n    }\n    let delta = 0.1;\n    const prevValue = +document.getElementById('output').value;\n    document.getElementById('output').value =\n        prevValue + (label === 0 ? -delta : delta);\n  }\n\n  const listen = () => {\n    if (model.isListening()) {\n      model.stopListening();\n      console.log('Listen');\n      return;\n    }\n    console.log('Stop');\n\n    model.listen(async ({spectrogram: {frameSize, data}}) => {\n\n      const vals = normalize(data.subarray(-frameSize * NUM_FRAMES));\n      const input = tf.tensor(vals, [1, ...INPUT_SHAPE]);\n      const probs = modelTobuilded.predict(input);\n      const predLabel = probs.argMax(1);\n      const scores = probs.arraySync()[0];\n\n      console.log(scores);\n      const score = Array.from(scores).map((s, i) => ({score: s, word: i}));\n      score.sort((s1, s2) => s2.score - s1.score);\n      console.log(score[0].word);\n\n      //console.log('prelabel ',predLabel);\n      const labela = (await predLabel.data())[0];\n      console.log(labela);\n      //await moveSlider(predLabel);\n\n      tf.dispose([input, probs, predLabel]);\n    }, {\n      overlapFactor: 0.5,\n      includeSpectrogram: true,\n      invokeCallbackOnNoiseAndUnknown: true,\n      probabilityThershold: 0.8,\n    });\n  };\n\n  const testListen = async () => {\n    const baseRecognizer = await speech.create('BROWSER_FFT');\n    await baseRecognizer.ensureModelLoaded();\n    const transferRecognizer = baseRecognizer.createTransfer('colors');\n\n    await transferRecognizer.collectExample('red');\n    await transferRecognizer.collectExample('green');\n    await transferRecognizer.collectExample('blue');\n    await transferRecognizer.collectExample('red');\n\n    await transferRecognizer.collectExample('_background_noise_');\n    await transferRecognizer.collectExample('green');\n    await transferRecognizer.collectExample('blue');\n    await transferRecognizer.collectExample('_background_noise_');\n\n    console.log(transferRecognizer.countExamples());\n\n    await transferRecognizer.train({\n      epochs: 25,\n      callback: {\n        onEpochEnd: async (epoch, logs) => {\n          console.log(`Epoch ${epoch}: loss=${logs.loss}, accuracy=${logs.acc}`);\n        }\n      }\n    });\n\n    await transferRecognizer.listen(result => {\n\n      const words = transferRecognizer.wordLabels();\n\n      for (let i = 0; i < words; ++i) {\n        console.log(`score for word '${words[i]}' = ${result.scores[i]}`);\n      }\n    }, {probabilityThreshold: 0.75});\n\n    setTimeout(() => transferRecognizer.stopListening(), 10e3);\n  }\n\n  const exportFile = () => {\n    var rawFile = new XMLHttpRequest();\n    rawFile.open(\"GET\", `${window.location.origin}`+'\\\\myFile.txt', false);\n    rawFile.onreadystatechange = function ()\n    {\n      if(rawFile.readyState === 4)\n      {\n        if(rawFile.status === 200 || rawFile.status == 0)\n        {\n          var allText = rawFile.responseText;\n          examples = allText ;\n          console.log(allText);\n        }\n      }\n    }\n    rawFile.send(null);\n  }\n\n  const cleanData = () => {\n    let voir = examples.filter(e => e.label === 1);\n    console.log(voir.length);\n    let noise = examples.filter(e => e.label === 0);\n    console.log(voir[0].vals.json);\n    for(var i in voir)\n      for(var j of voir[i].vals){\n\n        console.log(j);\n      }\n    voir.forEach(e => {\n      //let index = noise.val.indexOf(e.val) ;\n      //console.log(e.vals);\n      noise.forEach(r => {\n        if(e.val === r.val){\n          //voir.splice(voir.indexOf(e),1);\n        }\n      });\n      //if(index !== -1) {\n        //voir.splice(voir.indexOf(e),1);\n      //}\n    });\n    console.log(voir.length);\n    console.log(noise.length);\n\n  };\n\n  useEffect(() => {\n    loadModel();\n    buildModel();\n    console.log(modelTobuild);\n  },[]);\n\n\n  return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n          <img src={logo} className=\"App-logo\" alt=\"logo\" />\n          <p>\n            Edit <code>src/App.js</code> and save to reload.\n          </p>\n          <button onClick={recognizeCommands}>Listening</button>\n          <button onMouseDown={() => collectVoice(0)} onMouseUp={() => collectVoice(0)}>SILENCE</button>\n          <button onMouseDown={() => collectVoice(1)} onMouseUp={() => collectVoice(1)}>ZERO</button>\n          <button onMouseDown={() => collectVoice(2)} onMouseUp={() => collectVoice(2)}>ONE</button>\n          <button onMouseDown={() => collectVoice(4)} onMouseUp={() => collectVoice(4)}>TWO</button>\n          <button onMouseDown={() => collectVoice(5)} onMouseUp={() => collectVoice(5)}>THREE</button>\n          <button onMouseDown={() => collectVoice(6)} onMouseUp={() => collectVoice(6)}>FOUR</button>\n          <button onMouseDown={() => collectVoice(7)} onMouseUp={() => collectVoice(7)}>FIVE</button>\n          <button onMouseDown={() => collectVoice(8)} onMouseUp={() => collectVoice(8)}>SIX</button>\n          <button onMouseDown={() => collectVoice(9)} onMouseUp={() => collectVoice(9)}>SEVEN</button>\n          <button onMouseDown={() => collectVoice(10)} onMouseUp={() => collectVoice(10)}>EIGHT</button>\n          <button onMouseDown={() => collectVoice(11)} onMouseUp={() => collectVoice(11)}>NINE</button>\n          <button onMouseDown={() => collectVoice(1)} onMouseUp={() => collectVoice(1)}>NOISE</button>\n\n\n          <button onClick={train}>Train</button>\n          <input type=\"range\" id=\"output\" min=\"0\" max=\"10\" step=\"0.1\"/>\n          <button onClick={listen}>Listen</button>\n          <button onClick={saveExemple}>save</button>\n          <button onClick={()=>model.stopListening()}>Stop</button>\n          <button onClick={saveExemple}>save</button>\n          <button onClick={exportFile}>export</button>\n          <button onClick={cleanData}>showList</button>\n\n        </header>\n\n      </div>\n  );\n}\n\nexport default App;\n","D:\\Study\\React\\audio-app\\src\\home.tsx",["56","57","58","59"],"import {useEffect, useState} from \"react\";\r\nimport * as tf from \"@tensorflow/tfjs\";\r\nimport * as SpeechCommands from \"@tensorflow-models/speech-commands\";\r\n\r\nimport VoiceModel from \"./My_Model/model.json\";\r\nimport VoiceModelMetadata from \"./My_Model/metadata.json\";\r\nimport VoiceAssistant from \"./voiceAssistant\";\r\n\r\nexport const HomePage = () => {\r\n\r\n    const [model, setModel] = useState(null);\r\n    let voiceAssistant;\r\n\r\n    async function buildModel() {\r\n        const recognizer = await SpeechCommands.create(\"BROWSER_FFT\",undefined,VoiceModel,VoiceModelMetadata);\r\n        await recognizer.ensureModelLoaded();\r\n        console.log(\"Model Loaded\");\r\n        return recognizer;\r\n    }\r\n\r\n    const startAssistance = async () => {\r\n        //const recognizer = await buildModel();\r\n        voiceAssistant = new VoiceAssistant();\r\n        voiceAssistant.start();\r\n        //recognizer.listen((result)=>{},null);\r\n    }\r\n\r\n    useEffect(()=> {\r\n        console.log('ooooo');\r\n    },[]);\r\n\r\n    return (\r\n        <div>\r\n            <h1>OK</h1>\r\n            <button onClick={startAssistance} >Start</button>\r\n        </div>\r\n    );\r\n\r\n};\r\nexport default HomePage ;",["60","61"],"D:\\Study\\React\\audio-app\\src\\voiceAssistant.js",[],"D:\\Study\\React\\audio-app\\src\\voiceVisualizer.js",["62"],"import Wave from \"wave-visualizer\";\r\n\r\nexport default class VoiceVisualizer {\r\n    constructor() {}\r\n\r\n    async openAudioStream() {\r\n        try {\r\n            this.audioStream = await navigator.mediaDevices.getUserMedia({\r\n                audio: true,\r\n            });\r\n        } catch (err) {\r\n            console.error(\"Cannot open Audio Stream \", err);\r\n        }\r\n    }\r\n\r\n    async startVisualization() {\r\n        await this.openAudioStream();\r\n\r\n        let wave = new Wave();\r\n\r\n        wave.fromStream(this.audioStream, \"output\", {\r\n            type: \"bars\",\r\n            colors: [\"white\", \"FFFFFF\"],\r\n            stroke: 1,\r\n        });\r\n    }\r\n\r\n    stopVisualization() {\r\n        this.audioStream.getTracks().forEach((track) => {\r\n            track.stop();\r\n        });\r\n    }\r\n}","D:\\Study\\React\\audio-app\\src\\listening\\listening.tsx",["63","64","65","66","67","68","69"],"D:\\Study\\React\\audio-app\\src\\speechComp\\speechComp.tsx",["70","71"],"D:\\Study\\React\\audio-app\\src\\Utils\\methodUtils.js",[],{"ruleId":"72","replacedBy":"73"},{"ruleId":"74","replacedBy":"75"},{"ruleId":"76","severity":1,"message":"77","line":10,"column":10,"nodeType":"78","messageId":"79","endLine":10,"endColumn":16},{"ruleId":"76","severity":1,"message":"80","line":10,"column":18,"nodeType":"78","messageId":"79","endLine":10,"endColumn":27},{"ruleId":"76","severity":1,"message":"81","line":11,"column":10,"nodeType":"78","messageId":"79","endLine":11,"endColumn":16},{"ruleId":"76","severity":1,"message":"82","line":76,"column":9,"nodeType":"78","messageId":"79","endLine":76,"endColumn":22},{"ruleId":"76","severity":1,"message":"83","line":128,"column":12,"nodeType":"78","messageId":"79","endLine":128,"endColumn":19},{"ruleId":"76","severity":1,"message":"84","line":143,"column":18,"nodeType":"78","messageId":"79","endLine":143,"endColumn":28},{"ruleId":"85","severity":1,"message":"86","line":146,"column":15,"nodeType":"87","messageId":"88","endLine":146,"endColumn":17},{"ruleId":"76","severity":1,"message":"89","line":190,"column":9,"nodeType":"78","messageId":"79","endLine":190,"endColumn":19},{"ruleId":"90","severity":1,"message":"91","line":230,"column":52,"nodeType":"87","messageId":"92","endLine":230,"endColumn":53},{"ruleId":"85","severity":1,"message":"86","line":235,"column":53,"nodeType":"87","messageId":"88","endLine":235,"endColumn":55},{"ruleId":"93","severity":1,"message":"94","line":277,"column":5,"nodeType":"95","endLine":277,"endColumn":7,"suggestions":"96"},{"ruleId":"97","severity":1,"message":"98","line":2,"column":13,"nodeType":"78","messageId":"79","endLine":2,"endColumn":15},{"ruleId":"97","severity":1,"message":"99","line":11,"column":12,"nodeType":"78","messageId":"79","endLine":11,"endColumn":17},{"ruleId":"97","severity":1,"message":"100","line":11,"column":19,"nodeType":"78","messageId":"79","endLine":11,"endColumn":27},{"ruleId":"97","severity":1,"message":"101","line":14,"column":20,"nodeType":"78","messageId":"79","endLine":14,"endColumn":30},{"ruleId":"72","replacedBy":"73"},{"ruleId":"74","replacedBy":"75"},{"ruleId":"102","severity":1,"message":"103","line":4,"column":5,"nodeType":"104","messageId":"105","endLine":4,"endColumn":21},{"ruleId":"97","severity":1,"message":"106","line":1,"column":9,"nodeType":"78","messageId":"79","endLine":1,"endColumn":18},{"ruleId":"97","severity":1,"message":"107","line":1,"column":20,"nodeType":"78","messageId":"79","endLine":1,"endColumn":28},{"ruleId":"97","severity":1,"message":"98","line":2,"column":13,"nodeType":"78","messageId":"79","endLine":2,"endColumn":15},{"ruleId":"97","severity":1,"message":"108","line":3,"column":13,"nodeType":"78","messageId":"79","endLine":3,"endColumn":27},{"ruleId":"97","severity":1,"message":"109","line":5,"column":8,"nodeType":"78","messageId":"79","endLine":5,"endColumn":18},{"ruleId":"97","severity":1,"message":"110","line":6,"column":8,"nodeType":"78","messageId":"79","endLine":6,"endColumn":26},{"ruleId":"97","severity":1,"message":"111","line":7,"column":8,"nodeType":"78","messageId":"79","endLine":7,"endColumn":22},{"ruleId":"97","severity":1,"message":"112","line":14,"column":11,"nodeType":"78","messageId":"79","endLine":14,"endColumn":15},{"ruleId":"97","severity":1,"message":"113","line":38,"column":11,"nodeType":"78","messageId":"79","endLine":38,"endColumn":25},"no-native-reassign",["114"],"no-negated-in-lhs",["115"],"no-unused-vars","'action' is assigned a value but never used.","Identifier","unusedVar","'setAction' is assigned a value but never used.","'labels' is assigned a value but never used.","'setStateAsync' is assigned a value but never used.","'predict' is defined but never used.","'moveSlider' is defined but never used.","eqeqeq","Expected '===' and instead saw '=='.","BinaryExpression","unexpected","'testListen' is assigned a value but never used.","no-useless-concat","Unexpected string concatenation of literals.","unexpectedConcat","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'buildModel' and 'modelTobuild'. Either include them or remove the dependency array.","ArrayExpression",["116"],"@typescript-eslint/no-unused-vars","'tf' is defined but never used.","'model' is assigned a value but never used.","'setModel' is assigned a value but never used.","'buildModel' is defined but never used.","no-useless-constructor","Useless constructor.","MethodDefinition","noUselessConstructor","'useEffect' is defined but never used.","'useState' is defined but never used.","'SpeechCommands' is defined but never used.","'VoiceModel' is defined but never used.","'VoiceModelMetadata' is defined but never used.","'VoiceAssistant' is defined but never used.","'icon' is assigned a value but never used.","'startListening' is assigned a value but never used.","no-global-assign","no-unsafe-negation",{"desc":"117","fix":"118"},"Update the dependencies array to be: [buildModel, modelTobuild]",{"range":"119","text":"120"},[8321,8323],"[buildModel, modelTobuild]"]